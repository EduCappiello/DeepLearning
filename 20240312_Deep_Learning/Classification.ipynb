{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import Module, Sequential\n",
    "from torch.nn import Linear, ReLU, Sigmoid, LeakyReLU\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"../20240312_Deep_Learning/NN_Classification/housepricedata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>AboveMedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea  OverallQual  OverallCond  TotalBsmtSF  FullBath  HalfBath  \\\n",
       "0     8450            7            5          856         2         1   \n",
       "1     9600            6            8         1262         2         0   \n",
       "2    11250            7            5          920         2         1   \n",
       "3     9550            7            5          756         1         0   \n",
       "4    14260            8            5         1145         2         1   \n",
       "\n",
       "   BedroomAbvGr  TotRmsAbvGrd  Fireplaces  GarageArea  AboveMedianPrice  \n",
       "0             3             8           0         548                 1  \n",
       "1             3             6           1         460                 1  \n",
       "2             3             6           1         608                 1  \n",
       "3             3             7           1         642                 0  \n",
       "4             4             9           1         836                 1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   LotArea           1460 non-null   int64\n",
      " 1   OverallQual       1460 non-null   int64\n",
      " 2   OverallCond       1460 non-null   int64\n",
      " 3   TotalBsmtSF       1460 non-null   int64\n",
      " 4   FullBath          1460 non-null   int64\n",
      " 5   HalfBath          1460 non-null   int64\n",
      " 6   BedroomAbvGr      1460 non-null   int64\n",
      " 7   TotRmsAbvGrd      1460 non-null   int64\n",
      " 8   Fireplaces        1460 non-null   int64\n",
      " 9   GarageArea        1460 non-null   int64\n",
      " 10  AboveMedianPrice  1460 non-null   int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 125.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"AboveMedianPrice\", axis=1)\n",
    "y = df[\"AboveMedianPrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.values\n",
    "y_train_np = y_train.values\n",
    "X_test_np = X_test.values\n",
    "y_test_np = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(Module):\n",
    "    def __init__(self, num_features: int, num_classes: int):\n",
    "        super(Neural_Network, self).__init__()\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.layer_1_neurons = 30\n",
    "        self.layer_2_neurons = 20\n",
    "        self.layer_3_neurons = 10\n",
    "        self.regularization_factor = 0.001\n",
    "        self.learning_rate = 0.002\n",
    "        self.num_epochs = 500\n",
    "\n",
    "        # Layers\n",
    "        self.fc_input = Sequential(\n",
    "            Linear(num_features, self.layer_1_neurons),\n",
    "            LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_l1 = Sequential(\n",
    "            Linear(self.layer_1_neurons, self.layer_2_neurons),\n",
    "            LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_l2 = Sequential(\n",
    "            Linear(self.layer_2_neurons, self.layer_3_neurons),\n",
    "            LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_output = Sequential(\n",
    "            Linear(self.layer_3_neurons, num_classes),\n",
    "            Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.optimizer = Adam(self.parameters(), lr=self.learning_rate)\n",
    "        self.loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "        # Lists to store training and validation losses\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_input(x)\n",
    "        x = self.fc_l1(x)\n",
    "        x = self.fc_l2(x)\n",
    "        output = self.fc_output(x)\n",
    "        return output\n",
    "\n",
    "    def train_model(self, train_loader, val_loader=None):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.forward(inputs)\n",
    "                loss = self.loss_fn(outputs, labels.unsqueeze(1))\n",
    "                l2_regularization = 0\n",
    "                for param in self.parameters():\n",
    "                    l2_regularization += torch.norm(param, 2)\n",
    "                loss += self.regularization_factor * l2_regularization\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # Compute training loss\n",
    "            train_loss = self.compute_loss(train_loader)\n",
    "            self.train_losses.append(train_loss)\n",
    "\n",
    "            # Compute validation loss if validation loader is provided\n",
    "            if val_loader:\n",
    "                val_loss = self.compute_loss(val_loader)\n",
    "                self.val_losses.append(val_loss)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.num_epochs}, Train Loss: {train_loss}\")\n",
    "            if val_loader:\n",
    "                print(f\"Epoch {epoch+1}/{self.num_epochs}, Validation Loss: {val_loss}\")\n",
    "\n",
    "    def compute_loss(self, data_loader):\n",
    "        self.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in data_loader:\n",
    "                outputs = self.forward(inputs)\n",
    "                loss = self.loss_fn(outputs, labels.unsqueeze(1))\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "        return total_loss / len(data_loader.dataset)\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.forward(x)\n",
    "            predictions = (outputs >= 0.5).float()\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = Neural_Network(num_features=X_train.shape[1], num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation DataLoader\n",
    "val_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Train Loss: 0.9884304983975136\n",
      "Epoch 1/500, Validation Loss: 1.0225737682760578\n",
      "Epoch 2/500, Train Loss: 0.7985218534730885\n",
      "Epoch 2/500, Validation Loss: 0.779048840477042\n",
      "Epoch 3/500, Train Loss: 1.2906632570371235\n",
      "Epoch 3/500, Validation Loss: 1.0954777475905746\n",
      "Epoch 4/500, Train Loss: 1.7633380465311548\n",
      "Epoch 4/500, Validation Loss: 1.3993708287199882\n",
      "Epoch 5/500, Train Loss: 0.9594772588716795\n",
      "Epoch 5/500, Validation Loss: 1.0371264847990584\n",
      "Epoch 6/500, Train Loss: 0.6615333279518232\n",
      "Epoch 6/500, Validation Loss: 0.6410664744573097\n",
      "Epoch 7/500, Train Loss: 1.8751581939932418\n",
      "Epoch 7/500, Validation Loss: 1.4941930264642793\n",
      "Epoch 8/500, Train Loss: 0.6269204828837146\n",
      "Epoch 8/500, Validation Loss: 0.6323023193503079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/500, Train Loss: 0.6857607642265215\n",
      "Epoch 9/500, Validation Loss: 0.7247344557553121\n",
      "Epoch 10/500, Train Loss: 1.1358745914615997\n",
      "Epoch 10/500, Validation Loss: 1.2351151917078724\n",
      "Epoch 11/500, Train Loss: 0.8708599511891195\n",
      "Epoch 11/500, Validation Loss: 0.944028181572483\n",
      "Epoch 12/500, Train Loss: 0.63571872449901\n",
      "Epoch 12/500, Validation Loss: 0.6526676106126341\n",
      "Epoch 13/500, Train Loss: 0.980545064357862\n",
      "Epoch 13/500, Validation Loss: 1.0695241852982404\n",
      "Epoch 14/500, Train Loss: 0.6349395480874467\n",
      "Epoch 14/500, Validation Loss: 0.6475125845164469\n",
      "Epoch 15/500, Train Loss: 0.653792142868042\n",
      "Epoch 15/500, Validation Loss: 0.6733095017198014\n",
      "Epoch 16/500, Train Loss: 0.9922145327476606\n",
      "Epoch 16/500, Validation Loss: 1.075009087993674\n",
      "Epoch 17/500, Train Loss: 0.6290904561134234\n",
      "Epoch 17/500, Validation Loss: 0.6459834787943591\n",
      "Epoch 18/500, Train Loss: 1.4717190935187143\n",
      "Epoch 18/500, Validation Loss: 1.4628049837399835\n",
      "Epoch 19/500, Train Loss: 0.6933468123004861\n",
      "Epoch 19/500, Validation Loss: 0.6330183883235879\n",
      "Epoch 20/500, Train Loss: 0.6100604436168932\n",
      "Epoch 20/500, Validation Loss: 0.615709072923007\n",
      "Epoch 21/500, Train Loss: 0.8315017729589383\n",
      "Epoch 21/500, Validation Loss: 0.9006152912361981\n",
      "Epoch 22/500, Train Loss: 0.6253640578217703\n",
      "Epoch 22/500, Validation Loss: 0.6371910457741724\n",
      "Epoch 23/500, Train Loss: 0.6223255755150154\n",
      "Epoch 23/500, Validation Loss: 0.5966034474438184\n",
      "Epoch 24/500, Train Loss: 0.6098773610101987\n",
      "Epoch 24/500, Validation Loss: 0.6246896092205831\n",
      "Epoch 25/500, Train Loss: 0.6102978595315594\n",
      "Epoch 25/500, Validation Loss: 0.626252779405411\n",
      "Epoch 26/500, Train Loss: 0.6108639158614694\n",
      "Epoch 26/500, Validation Loss: 0.5822140754085697\n",
      "Epoch 27/500, Train Loss: 0.5901280151654597\n",
      "Epoch 27/500, Validation Loss: 0.5840019314256433\n",
      "Epoch 28/500, Train Loss: 0.7120609961143912\n",
      "Epoch 28/500, Validation Loss: 0.6463567361439744\n",
      "Epoch 29/500, Train Loss: 0.6319895378530842\n",
      "Epoch 29/500, Validation Loss: 0.6522368886699416\n",
      "Epoch 30/500, Train Loss: 0.6466772450159674\n",
      "Epoch 30/500, Validation Loss: 0.6759877368195416\n",
      "Epoch 31/500, Train Loss: 0.6611691092791623\n",
      "Epoch 31/500, Validation Loss: 0.6939256958765526\n",
      "Epoch 32/500, Train Loss: 0.5887478124605466\n",
      "Epoch 32/500, Validation Loss: 0.568119521010412\n",
      "Epoch 33/500, Train Loss: 0.639434767912512\n",
      "Epoch 33/500, Validation Loss: 0.6199549354919015\n",
      "Epoch 34/500, Train Loss: 0.6588322103840031\n",
      "Epoch 34/500, Validation Loss: 0.6862924621529776\n",
      "Epoch 35/500, Train Loss: 1.2188726418638882\n",
      "Epoch 35/500, Validation Loss: 1.2428080774333379\n",
      "Epoch 36/500, Train Loss: 0.6856915411883837\n",
      "Epoch 36/500, Validation Loss: 0.6199036436538173\n",
      "Epoch 37/500, Train Loss: 0.5864912712410705\n",
      "Epoch 37/500, Validation Loss: 0.5576874336151227\n",
      "Epoch 38/500, Train Loss: 0.9345829821612737\n",
      "Epoch 38/500, Validation Loss: 1.0187554669706789\n",
      "Epoch 39/500, Train Loss: 0.5712012967018232\n",
      "Epoch 39/500, Validation Loss: 0.5700350395620686\n",
      "Epoch 40/500, Train Loss: 0.8012479000712094\n",
      "Epoch 40/500, Validation Loss: 0.8508519652771623\n",
      "Epoch 41/500, Train Loss: 0.5676070582376768\n",
      "Epoch 41/500, Validation Loss: 0.5505311979006414\n",
      "Epoch 42/500, Train Loss: 0.5614442800822323\n",
      "Epoch 42/500, Validation Loss: 0.5555921352072938\n",
      "Epoch 43/500, Train Loss: 0.6233646224622857\n",
      "Epoch 43/500, Validation Loss: 0.6483408792378151\n",
      "Epoch 44/500, Train Loss: 0.9966120719909668\n",
      "Epoch 44/500, Validation Loss: 0.8402890342555634\n",
      "Epoch 45/500, Train Loss: 0.6326109856775363\n",
      "Epoch 45/500, Validation Loss: 0.6578862062872273\n",
      "Epoch 46/500, Train Loss: 0.9283427326646569\n",
      "Epoch 46/500, Validation Loss: 0.7830041255036445\n",
      "Epoch 47/500, Train Loss: 0.6146625370195468\n",
      "Epoch 47/500, Validation Loss: 0.567571466099726\n",
      "Epoch 48/500, Train Loss: 0.638142272217633\n",
      "Epoch 48/500, Validation Loss: 0.5820902512498098\n",
      "Epoch 49/500, Train Loss: 0.5670278668403625\n",
      "Epoch 49/500, Validation Loss: 0.5357098612066817\n",
      "Epoch 50/500, Train Loss: 0.6262352090992339\n",
      "Epoch 50/500, Validation Loss: 0.6510817277921389\n",
      "Epoch 51/500, Train Loss: 0.5601234925936346\n",
      "Epoch 51/500, Validation Loss: 0.5460823806997848\n",
      "Epoch 52/500, Train Loss: 0.5578397414455675\n",
      "Epoch 52/500, Validation Loss: 0.5334263484771937\n",
      "Epoch 53/500, Train Loss: 0.7335859430979376\n",
      "Epoch 53/500, Validation Loss: 0.7826484858173214\n",
      "Epoch 54/500, Train Loss: 0.5582752970800008\n",
      "Epoch 54/500, Validation Loss: 0.5404010831493221\n",
      "Epoch 55/500, Train Loss: 0.6006192875235048\n",
      "Epoch 55/500, Validation Loss: 0.6213832865022633\n",
      "Epoch 56/500, Train Loss: 0.544202402029952\n",
      "Epoch 56/500, Validation Loss: 0.5277292679433954\n",
      "Epoch 57/500, Train Loss: 0.5526387111781395\n",
      "Epoch 57/500, Validation Loss: 0.5391168284089598\n",
      "Epoch 58/500, Train Loss: 0.5406274795532227\n",
      "Epoch 58/500, Validation Loss: 0.5220502696625174\n",
      "Epoch 59/500, Train Loss: 0.5601188818069354\n",
      "Epoch 59/500, Validation Loss: 0.5298841897755453\n",
      "Epoch 60/500, Train Loss: 0.6050800942394832\n",
      "Epoch 60/500, Validation Loss: 0.623680490337006\n",
      "Epoch 61/500, Train Loss: 0.6341503736090986\n",
      "Epoch 61/500, Validation Loss: 0.5490722280659087\n",
      "Epoch 62/500, Train Loss: 0.5321125184019951\n",
      "Epoch 62/500, Validation Loss: 0.5180289614690493\n",
      "Epoch 63/500, Train Loss: 0.6355480012828356\n",
      "Epoch 63/500, Validation Loss: 0.5672777858498979\n",
      "Epoch 64/500, Train Loss: 0.5333520443472144\n",
      "Epoch 64/500, Validation Loss: 0.5107591413471797\n",
      "Epoch 65/500, Train Loss: 0.5251501586339246\n",
      "Epoch 65/500, Validation Loss: 0.5047197717509858\n",
      "Epoch 66/500, Train Loss: 0.5307081219268172\n",
      "Epoch 66/500, Validation Loss: 0.509385251835601\n",
      "Epoch 67/500, Train Loss: 0.5485591888427734\n",
      "Epoch 67/500, Validation Loss: 0.5545597990898237\n",
      "Epoch 68/500, Train Loss: 0.5940964066818969\n",
      "Epoch 68/500, Validation Loss: 0.5425193636384729\n",
      "Epoch 69/500, Train Loss: 0.5520860226186988\n",
      "Epoch 69/500, Validation Loss: 0.5629906997288743\n",
      "Epoch 70/500, Train Loss: 0.5223428802947475\n",
      "Epoch 70/500, Validation Loss: 0.5087610181063822\n",
      "Epoch 71/500, Train Loss: 0.5163861496807778\n",
      "Epoch 71/500, Validation Loss: 0.4989242488390779\n",
      "Epoch 72/500, Train Loss: 0.6395818991203831\n",
      "Epoch 72/500, Validation Loss: 0.6663071643816282\n",
      "Epoch 73/500, Train Loss: 0.5293643882829849\n",
      "Epoch 73/500, Validation Loss: 0.5227601585322863\n",
      "Epoch 74/500, Train Loss: 0.5205264299699704\n",
      "Epoch 74/500, Validation Loss: 0.4961667526258181\n",
      "Epoch 75/500, Train Loss: 0.6982055330929691\n",
      "Epoch 75/500, Validation Loss: 0.7395177434568536\n",
      "Epoch 76/500, Train Loss: 0.5423635513815162\n",
      "Epoch 76/500, Validation Loss: 0.514664594441244\n",
      "Epoch 77/500, Train Loss: 0.5213264259573531\n",
      "Epoch 77/500, Validation Loss: 0.5096489150230199\n",
      "Epoch 78/500, Train Loss: 0.518440065318591\n",
      "Epoch 78/500, Validation Loss: 0.4902982287210961\n",
      "Epoch 79/500, Train Loss: 0.5136004572045313\n",
      "Epoch 79/500, Validation Loss: 0.4995248309553486\n",
      "Epoch 80/500, Train Loss: 0.5305800854343258\n",
      "Epoch 80/500, Validation Loss: 0.5052784844620587\n",
      "Epoch 81/500, Train Loss: 0.5403138358299047\n",
      "Epoch 81/500, Validation Loss: 0.5109204666255271\n",
      "Epoch 82/500, Train Loss: 0.5593314644408552\n",
      "Epoch 82/500, Validation Loss: 0.5583170709544665\n",
      "Epoch 83/500, Train Loss: 0.5429237570664655\n",
      "Epoch 83/500, Validation Loss: 0.5411848262564777\n",
      "Epoch 84/500, Train Loss: 0.5072365068409541\n",
      "Epoch 84/500, Validation Loss: 0.4805845373297391\n",
      "Epoch 85/500, Train Loss: 0.5274999607099246\n",
      "Epoch 85/500, Validation Loss: 0.49013673197733215\n",
      "Epoch 86/500, Train Loss: 0.526157310972475\n",
      "Epoch 86/500, Validation Loss: 0.5107263579760513\n",
      "Epoch 87/500, Train Loss: 0.5171796699909315\n",
      "Epoch 87/500, Validation Loss: 0.4885197322662563\n",
      "Epoch 88/500, Train Loss: 0.5053152613443871\n",
      "Epoch 88/500, Validation Loss: 0.4876085356490253\n",
      "Epoch 89/500, Train Loss: 0.5047395727405809\n",
      "Epoch 89/500, Validation Loss: 0.4780617176669918\n",
      "Epoch 90/500, Train Loss: 0.5428693482320602\n",
      "Epoch 90/500, Validation Loss: 0.4978834031379386\n",
      "Epoch 91/500, Train Loss: 0.5195340816288778\n",
      "Epoch 91/500, Validation Loss: 0.4721223981413123\n",
      "Epoch 92/500, Train Loss: 0.5083521424907528\n",
      "Epoch 92/500, Validation Loss: 0.4734546525837624\n",
      "Epoch 93/500, Train Loss: 0.5036787121263269\n",
      "Epoch 93/500, Validation Loss: 0.47138300333937555\n",
      "Epoch 94/500, Train Loss: 0.4975612020655854\n",
      "Epoch 94/500, Validation Loss: 0.47358906269073486\n",
      "Epoch 95/500, Train Loss: 0.5404164244050849\n",
      "Epoch 95/500, Validation Loss: 0.5290401822900119\n",
      "Epoch 96/500, Train Loss: 0.5163801679872486\n",
      "Epoch 96/500, Validation Loss: 0.4773264290535287\n",
      "Epoch 97/500, Train Loss: 0.4957490155141648\n",
      "Epoch 97/500, Validation Loss: 0.4733695689946005\n",
      "Epoch 98/500, Train Loss: 0.5687047594214139\n",
      "Epoch 98/500, Validation Loss: 0.5131961654310357\n",
      "Epoch 99/500, Train Loss: 0.5214038483084065\n",
      "Epoch 99/500, Validation Loss: 0.5031824487529389\n",
      "Epoch 100/500, Train Loss: 0.517380127351578\n",
      "Epoch 100/500, Validation Loss: 0.5186217157808068\n",
      "Epoch 101/500, Train Loss: 0.4960719706260995\n",
      "Epoch 101/500, Validation Loss: 0.4679942408653155\n",
      "Epoch 102/500, Train Loss: 0.5680396720154645\n",
      "Epoch 102/500, Validation Loss: 0.5077002309773067\n",
      "Epoch 103/500, Train Loss: 0.5158577251107725\n",
      "Epoch 103/500, Validation Loss: 0.4712547994639775\n",
      "Epoch 104/500, Train Loss: 0.5057165990137074\n",
      "Epoch 104/500, Validation Loss: 0.48373229536291673\n",
      "Epoch 105/500, Train Loss: 0.5191783725398861\n",
      "Epoch 105/500, Validation Loss: 0.519140605240652\n",
      "Epoch 106/500, Train Loss: 0.5081495912107703\n",
      "Epoch 106/500, Validation Loss: 0.49581330279781394\n",
      "Epoch 107/500, Train Loss: 0.500855465457864\n",
      "Epoch 107/500, Validation Loss: 0.4832672819699327\n",
      "Epoch 108/500, Train Loss: 0.5140519672877168\n",
      "Epoch 108/500, Validation Loss: 0.4710875978208568\n",
      "Epoch 109/500, Train Loss: 0.5176054880227128\n",
      "Epoch 109/500, Validation Loss: 0.5144520369294572\n",
      "Epoch 110/500, Train Loss: 0.4967355344393482\n",
      "Epoch 110/500, Validation Loss: 0.46869525435852677\n",
      "Epoch 111/500, Train Loss: 0.5018695327517104\n",
      "Epoch 111/500, Validation Loss: 0.46098970387079946\n",
      "Epoch 112/500, Train Loss: 0.5284132932963437\n",
      "Epoch 112/500, Validation Loss: 0.5194764765974593\n",
      "Epoch 113/500, Train Loss: 0.5055492422352098\n",
      "Epoch 113/500, Validation Loss: 0.4942172406470939\n",
      "Epoch 114/500, Train Loss: 0.4934252663834454\n",
      "Epoch 114/500, Validation Loss: 0.47316135119085445\n",
      "Epoch 115/500, Train Loss: 0.506498394763633\n",
      "Epoch 115/500, Validation Loss: 0.4992070540989915\n",
      "Epoch 116/500, Train Loss: 0.4949354643691076\n",
      "Epoch 116/500, Validation Loss: 0.47922976376259163\n",
      "Epoch 117/500, Train Loss: 0.4922844963530972\n",
      "Epoch 117/500, Validation Loss: 0.46012410154081373\n",
      "Epoch 118/500, Train Loss: 0.49568710751729467\n",
      "Epoch 118/500, Validation Loss: 0.48095681814298236\n",
      "Epoch 119/500, Train Loss: 0.49147640393204883\n",
      "Epoch 119/500, Validation Loss: 0.467571544320616\n",
      "Epoch 120/500, Train Loss: 0.5053313382684368\n",
      "Epoch 120/500, Validation Loss: 0.48749190405623555\n",
      "Epoch 121/500, Train Loss: 0.5518250040812035\n",
      "Epoch 121/500, Validation Loss: 0.5583883360640644\n",
      "Epoch 122/500, Train Loss: 0.5191731934678064\n",
      "Epoch 122/500, Validation Loss: 0.5084872066158138\n",
      "Epoch 123/500, Train Loss: 0.4981287097277707\n",
      "Epoch 123/500, Validation Loss: 0.4854216657272757\n",
      "Epoch 124/500, Train Loss: 0.5056225045086586\n",
      "Epoch 124/500, Validation Loss: 0.4688608564742624\n",
      "Epoch 125/500, Train Loss: 0.5030194945531349\n",
      "Epoch 125/500, Validation Loss: 0.4660353284992584\n",
      "Epoch 126/500, Train Loss: 0.5012798472626568\n",
      "Epoch 126/500, Validation Loss: 0.4894958269106199\n",
      "Epoch 127/500, Train Loss: 0.535605301595714\n",
      "Epoch 127/500, Validation Loss: 0.4888685459959997\n",
      "Epoch 128/500, Train Loss: 0.517256986604978\n",
      "Epoch 128/500, Validation Loss: 0.4749133439913188\n",
      "Epoch 129/500, Train Loss: 0.48771005297360354\n",
      "Epoch 129/500, Validation Loss: 0.47096205165941424\n",
      "Epoch 130/500, Train Loss: 0.4919210321282687\n",
      "Epoch 130/500, Validation Loss: 0.467574222447121\n",
      "Epoch 131/500, Train Loss: 0.49790934340594567\n",
      "Epoch 131/500, Validation Loss: 0.49024732717095987\n",
      "Epoch 132/500, Train Loss: 0.48944665838594303\n",
      "Epoch 132/500, Validation Loss: 0.4718247129492564\n",
      "Epoch 133/500, Train Loss: 0.5196917955189535\n",
      "Epoch 133/500, Validation Loss: 0.47362384077620834\n",
      "Epoch 134/500, Train Loss: 0.5330611434701371\n",
      "Epoch 134/500, Validation Loss: 0.5236389032781941\n",
      "Epoch 135/500, Train Loss: 0.5423718768439881\n",
      "Epoch 135/500, Validation Loss: 0.5386367432058674\n",
      "Epoch 136/500, Train Loss: 0.4887708850102882\n",
      "Epoch 136/500, Validation Loss: 0.46038108002649597\n",
      "Epoch 137/500, Train Loss: 0.4848201307531905\n",
      "Epoch 137/500, Validation Loss: 0.4620976007148011\n",
      "Epoch 138/500, Train Loss: 0.5198371512432621\n",
      "Epoch 138/500, Validation Loss: 0.5148285684520251\n",
      "Epoch 139/500, Train Loss: 0.4966208359150037\n",
      "Epoch 139/500, Validation Loss: 0.46003280927057133\n",
      "Epoch 140/500, Train Loss: 0.49280589900604665\n",
      "Epoch 140/500, Validation Loss: 0.46510686123207823\n",
      "Epoch 141/500, Train Loss: 0.4909650740558154\n",
      "Epoch 141/500, Validation Loss: 0.4571137591584088\n",
      "Epoch 142/500, Train Loss: 0.489207047305695\n",
      "Epoch 142/500, Validation Loss: 0.4717900712196141\n",
      "Epoch 143/500, Train Loss: 0.5439794839244999\n",
      "Epoch 143/500, Validation Loss: 0.486405949886531\n",
      "Epoch 144/500, Train Loss: 0.4808564602512203\n",
      "Epoch 144/500, Validation Loss: 0.458573435267357\n",
      "Epoch 145/500, Train Loss: 0.486086857645479\n",
      "Epoch 145/500, Validation Loss: 0.4679146123259035\n",
      "Epoch 146/500, Train Loss: 0.48319285250689886\n",
      "Epoch 146/500, Validation Loss: 0.454341274418243\n",
      "Epoch 147/500, Train Loss: 0.5061792351611673\n",
      "Epoch 147/500, Validation Loss: 0.48227123201709904\n",
      "Epoch 148/500, Train Loss: 0.48875136816338316\n",
      "Epoch 148/500, Validation Loss: 0.47819990572864063\n",
      "Epoch 149/500, Train Loss: 0.5063273849552625\n",
      "Epoch 149/500, Validation Loss: 0.4687677360560796\n",
      "Epoch 150/500, Train Loss: 0.48733240365982056\n",
      "Epoch 150/500, Validation Loss: 0.4599374467379426\n",
      "Epoch 151/500, Train Loss: 0.48154131517018356\n",
      "Epoch 151/500, Validation Loss: 0.4571964887723531\n",
      "Epoch 152/500, Train Loss: 0.5231602841044125\n",
      "Epoch 152/500, Validation Loss: 0.4520686407611795\n",
      "Epoch 153/500, Train Loss: 0.48993427949408963\n",
      "Epoch 153/500, Validation Loss: 0.47353289143679894\n",
      "Epoch 154/500, Train Loss: 0.5510470426245911\n",
      "Epoch 154/500, Validation Loss: 0.49178839709660777\n",
      "Epoch 155/500, Train Loss: 0.5036362699449879\n",
      "Epoch 155/500, Validation Loss: 0.4984429935886435\n",
      "Epoch 156/500, Train Loss: 0.5089341426548892\n",
      "Epoch 156/500, Validation Loss: 0.5064328688464753\n",
      "Epoch 157/500, Train Loss: 0.4921980369580935\n",
      "Epoch 157/500, Validation Loss: 0.4727789816791064\n",
      "Epoch 158/500, Train Loss: 0.4935812717431212\n",
      "Epoch 158/500, Validation Loss: 0.47103870813160725\n",
      "Epoch 159/500, Train Loss: 0.48051192009285704\n",
      "Epoch 159/500, Validation Loss: 0.4490740078769318\n",
      "Epoch 160/500, Train Loss: 0.4797718626995609\n",
      "Epoch 160/500, Validation Loss: 0.4497510749999791\n",
      "Epoch 161/500, Train Loss: 0.49019171562913344\n",
      "Epoch 161/500, Validation Loss: 0.4670441885517068\n",
      "Epoch 162/500, Train Loss: 0.4842755565904591\n",
      "Epoch 162/500, Validation Loss: 0.4427973652539188\n",
      "Epoch 163/500, Train Loss: 0.49373483004635327\n",
      "Epoch 163/500, Validation Loss: 0.45206744948478594\n",
      "Epoch 164/500, Train Loss: 0.5389609589968642\n",
      "Epoch 164/500, Validation Loss: 0.5255126838814722\n",
      "Epoch 165/500, Train Loss: 0.48457254775582925\n",
      "Epoch 165/500, Validation Loss: 0.45170415509237\n",
      "Epoch 166/500, Train Loss: 0.4772486972482237\n",
      "Epoch 166/500, Validation Loss: 0.4490894462964306\n",
      "Epoch 167/500, Train Loss: 0.4783598976592495\n",
      "Epoch 167/500, Validation Loss: 0.4528928423581058\n",
      "Epoch 168/500, Train Loss: 0.48321719692177967\n",
      "Epoch 168/500, Validation Loss: 0.4571873463996469\n",
      "Epoch 169/500, Train Loss: 0.5130416522287342\n",
      "Epoch 169/500, Validation Loss: 0.4580177027885228\n",
      "Epoch 170/500, Train Loss: 0.5200459720337227\n",
      "Epoch 170/500, Validation Loss: 0.4682160346475366\n",
      "Epoch 171/500, Train Loss: 0.4827044867489436\n",
      "Epoch 171/500, Validation Loss: 0.43915952558386817\n",
      "Epoch 172/500, Train Loss: 0.47652243098167524\n",
      "Epoch 172/500, Validation Loss: 0.44219372860372885\n",
      "Epoch 173/500, Train Loss: 0.4861237602691128\n",
      "Epoch 173/500, Validation Loss: 0.4406868937897356\n",
      "Epoch 174/500, Train Loss: 0.4819748630262401\n",
      "Epoch 174/500, Validation Loss: 0.4443596715796484\n",
      "Epoch 175/500, Train Loss: 0.47775198049741247\n",
      "Epoch 175/500, Validation Loss: 0.4465382229791929\n",
      "Epoch 176/500, Train Loss: 0.4827192188942269\n",
      "Epoch 176/500, Validation Loss: 0.4403033975052507\n",
      "Epoch 177/500, Train Loss: 0.4789421640030325\n",
      "Epoch 177/500, Validation Loss: 0.43773715300102756\n",
      "Epoch 178/500, Train Loss: 0.4825824123539337\n",
      "Epoch 178/500, Validation Loss: 0.4565862964277398\n",
      "Epoch 179/500, Train Loss: 0.48037081058711223\n",
      "Epoch 179/500, Validation Loss: 0.44171838891016296\n",
      "Epoch 180/500, Train Loss: 0.5042990621638624\n",
      "Epoch 180/500, Validation Loss: 0.45638222727057054\n",
      "Epoch 181/500, Train Loss: 0.4754041980390679\n",
      "Epoch 181/500, Validation Loss: 0.4395883409944299\n",
      "Epoch 182/500, Train Loss: 0.48282814679080494\n",
      "Epoch 182/500, Validation Loss: 0.45977695020910814\n",
      "Epoch 183/500, Train Loss: 0.4765684327034101\n",
      "Epoch 183/500, Validation Loss: 0.44780021579298257\n",
      "Epoch 184/500, Train Loss: 0.4741839864482618\n",
      "Epoch 184/500, Validation Loss: 0.4403602415568208\n",
      "Epoch 185/500, Train Loss: 0.4962779977550245\n",
      "Epoch 185/500, Validation Loss: 0.47760858356136165\n",
      "Epoch 186/500, Train Loss: 0.4747403868257183\n",
      "Epoch 186/500, Validation Loss: 0.4425575512729279\n",
      "Epoch 187/500, Train Loss: 0.4825998340567497\n",
      "Epoch 187/500, Validation Loss: 0.45111909304579645\n",
      "Epoch 188/500, Train Loss: 0.4898779861731072\n",
      "Epoch 188/500, Validation Loss: 0.4659483824690727\n",
      "Epoch 189/500, Train Loss: 0.5534496903419495\n",
      "Epoch 189/500, Validation Loss: 0.47492975486467964\n",
      "Epoch 190/500, Train Loss: 0.49038389692567796\n",
      "Epoch 190/500, Validation Loss: 0.43685062127570584\n",
      "Epoch 191/500, Train Loss: 0.4776690439002155\n",
      "Epoch 191/500, Validation Loss: 0.4441926903920631\n",
      "Epoch 192/500, Train Loss: 0.4788864495819562\n",
      "Epoch 192/500, Validation Loss: 0.4435281410609206\n",
      "Epoch 193/500, Train Loss: 0.4790549972285963\n",
      "Epoch 193/500, Validation Loss: 0.43619435535718315\n",
      "Epoch 194/500, Train Loss: 0.48417874027604924\n",
      "Epoch 194/500, Validation Loss: 0.45613974087858855\n",
      "Epoch 195/500, Train Loss: 0.4747591337112531\n",
      "Epoch 195/500, Validation Loss: 0.44035152866415783\n",
      "Epoch 196/500, Train Loss: 0.6656687512789687\n",
      "Epoch 196/500, Validation Loss: 0.586640183239767\n",
      "Epoch 197/500, Train Loss: 0.4738037561717099\n",
      "Epoch 197/500, Validation Loss: 0.4413322022516433\n",
      "Epoch 198/500, Train Loss: 0.4723192057380938\n",
      "Epoch 198/500, Validation Loss: 0.44529720120234034\n",
      "Epoch 199/500, Train Loss: 0.49608135958240457\n",
      "Epoch 199/500, Validation Loss: 0.4489315772709781\n",
      "Epoch 200/500, Train Loss: 0.48393671724894277\n",
      "Epoch 200/500, Validation Loss: 0.4538610928679166\n",
      "Epoch 201/500, Train Loss: 0.49217881405190245\n",
      "Epoch 201/500, Validation Loss: 0.44785942035178616\n",
      "Epoch 202/500, Train Loss: 0.47404987436451324\n",
      "Epoch 202/500, Validation Loss: 0.4435712556316428\n",
      "Epoch 203/500, Train Loss: 0.4755240891077747\n",
      "Epoch 203/500, Validation Loss: 0.4420328932265713\n",
      "Epoch 204/500, Train Loss: 0.4812809514672789\n",
      "Epoch 204/500, Validation Loss: 0.43676561525423235\n",
      "Epoch 205/500, Train Loss: 0.46939657036572285\n",
      "Epoch 205/500, Validation Loss: 0.4367512276727859\n",
      "Epoch 206/500, Train Loss: 0.46721831658115126\n",
      "Epoch 206/500, Validation Loss: 0.43307647476457567\n",
      "Epoch 207/500, Train Loss: 0.48837843578155726\n",
      "Epoch 207/500, Validation Loss: 0.4356136215876227\n",
      "Epoch 208/500, Train Loss: 0.4744589532891365\n",
      "Epoch 208/500, Validation Loss: 0.4374574414671284\n",
      "Epoch 209/500, Train Loss: 0.47491544403441965\n",
      "Epoch 209/500, Validation Loss: 0.4430167503552894\n",
      "Epoch 210/500, Train Loss: 0.48906544381625033\n",
      "Epoch 210/500, Validation Loss: 0.44211893702206545\n",
      "Epoch 211/500, Train Loss: 0.477571917723303\n",
      "Epoch 211/500, Validation Loss: 0.44981106176768265\n",
      "Epoch 212/500, Train Loss: 0.48538947962734796\n",
      "Epoch 212/500, Validation Loss: 0.43889692793153734\n",
      "Epoch 213/500, Train Loss: 0.5099775064481448\n",
      "Epoch 213/500, Validation Loss: 0.48696057600517795\n",
      "Epoch 214/500, Train Loss: 0.4704740341395548\n",
      "Epoch 214/500, Validation Loss: 0.43519701124870613\n",
      "Epoch 215/500, Train Loss: 0.48329541536226667\n",
      "Epoch 215/500, Validation Loss: 0.4407525862732979\n",
      "Epoch 216/500, Train Loss: 0.5276729431870866\n",
      "Epoch 216/500, Validation Loss: 0.5083490977548573\n",
      "Epoch 217/500, Train Loss: 0.5226332075791816\n",
      "Epoch 217/500, Validation Loss: 0.4621668049733933\n",
      "Epoch 218/500, Train Loss: 0.4755901122746402\n",
      "Epoch 218/500, Validation Loss: 0.4270165440154402\n",
      "Epoch 219/500, Train Loss: 0.47087825120311894\n",
      "Epoch 219/500, Validation Loss: 0.4240841155182825\n",
      "Epoch 220/500, Train Loss: 0.485545036319184\n",
      "Epoch 220/500, Validation Loss: 0.4536888974986664\n",
      "Epoch 221/500, Train Loss: 0.4762351872169808\n",
      "Epoch 221/500, Validation Loss: 0.447098290267056\n",
      "Epoch 222/500, Train Loss: 0.5062770716948052\n",
      "Epoch 222/500, Validation Loss: 0.46909005756247535\n",
      "Epoch 223/500, Train Loss: 0.5010716547704723\n",
      "Epoch 223/500, Validation Loss: 0.4726021608261213\n",
      "Epoch 224/500, Train Loss: 0.49053382873535156\n",
      "Epoch 224/500, Validation Loss: 0.47404541381417886\n",
      "Epoch 225/500, Train Loss: 0.5009826291097353\n",
      "Epoch 225/500, Validation Loss: 0.448492362891158\n",
      "Epoch 226/500, Train Loss: 0.4696508237760361\n",
      "Epoch 226/500, Validation Loss: 0.4267986784242604\n",
      "Epoch 227/500, Train Loss: 0.4698005065526048\n",
      "Epoch 227/500, Validation Loss: 0.42962159685892604\n",
      "Epoch 228/500, Train Loss: 0.48514746272400633\n",
      "Epoch 228/500, Validation Loss: 0.45780060879171713\n",
      "Epoch 229/500, Train Loss: 0.4657205147285984\n",
      "Epoch 229/500, Validation Loss: 0.43113911233536184\n",
      "Epoch 230/500, Train Loss: 0.4919367975568118\n",
      "Epoch 230/500, Validation Loss: 0.4372115225008089\n",
      "Epoch 231/500, Train Loss: 0.49660359098486706\n",
      "Epoch 231/500, Validation Loss: 0.4736586400907334\n",
      "Epoch 232/500, Train Loss: 0.4756067162507201\n",
      "Epoch 232/500, Validation Loss: 0.44505651029821947\n",
      "Epoch 233/500, Train Loss: 0.47845029422681623\n",
      "Epoch 233/500, Validation Loss: 0.4454381041330834\n",
      "Epoch 234/500, Train Loss: 0.4707977012412189\n",
      "Epoch 234/500, Validation Loss: 0.43510504454782567\n",
      "Epoch 235/500, Train Loss: 0.4826936182910449\n",
      "Epoch 235/500, Validation Loss: 0.44721483367763154\n",
      "Epoch 236/500, Train Loss: 0.47004326279849223\n",
      "Epoch 236/500, Validation Loss: 0.4309042324758556\n",
      "Epoch 237/500, Train Loss: 0.5019472572084975\n",
      "Epoch 237/500, Validation Loss: 0.47993359500414706\n",
      "Epoch 238/500, Train Loss: 0.51270261202773\n",
      "Epoch 238/500, Validation Loss: 0.4770450404245559\n",
      "Epoch 239/500, Train Loss: 0.5020315434834729\n",
      "Epoch 239/500, Validation Loss: 0.4660868081327987\n",
      "Epoch 240/500, Train Loss: 0.46714610310449994\n",
      "Epoch 240/500, Validation Loss: 0.4278337400253505\n",
      "Epoch 241/500, Train Loss: 0.474509740528995\n",
      "Epoch 241/500, Validation Loss: 0.4310736680684024\n",
      "Epoch 242/500, Train Loss: 0.46954764486992195\n",
      "Epoch 242/500, Validation Loss: 0.4300124743213392\n",
      "Epoch 243/500, Train Loss: 0.46680241169994824\n",
      "Epoch 243/500, Validation Loss: 0.42352809971326016\n",
      "Epoch 244/500, Train Loss: 0.4725276966617532\n",
      "Epoch 244/500, Validation Loss: 0.4446453672565826\n",
      "Epoch 245/500, Train Loss: 0.47256358518992386\n",
      "Epoch 245/500, Validation Loss: 0.4410024783382677\n",
      "Epoch 246/500, Train Loss: 0.4714457098751852\n",
      "Epoch 246/500, Validation Loss: 0.4297973472778111\n",
      "Epoch 247/500, Train Loss: 0.5329347612106636\n",
      "Epoch 247/500, Validation Loss: 0.471705143582331\n",
      "Epoch 248/500, Train Loss: 0.4780168165899303\n",
      "Epoch 248/500, Validation Loss: 0.4408986731751324\n",
      "Epoch 249/500, Train Loss: 0.48175068669123194\n",
      "Epoch 249/500, Validation Loss: 0.4532777495580177\n",
      "Epoch 250/500, Train Loss: 0.4679732151227455\n",
      "Epoch 250/500, Validation Loss: 0.4273348916066836\n",
      "Epoch 251/500, Train Loss: 0.471498433857748\n",
      "Epoch 251/500, Validation Loss: 0.43431761248470985\n",
      "Epoch 252/500, Train Loss: 0.47266706130275987\n",
      "Epoch 252/500, Validation Loss: 0.43783695158893116\n",
      "Epoch 253/500, Train Loss: 0.4692570456903275\n",
      "Epoch 253/500, Validation Loss: 0.4325452536752779\n",
      "Epoch 254/500, Train Loss: 0.4780705305811477\n",
      "Epoch 254/500, Validation Loss: 0.4328575354732879\n",
      "Epoch 255/500, Train Loss: 0.47499068714167975\n",
      "Epoch 255/500, Validation Loss: 0.43896915243096546\n",
      "Epoch 256/500, Train Loss: 0.5104626564130391\n",
      "Epoch 256/500, Validation Loss: 0.45200219301328265\n",
      "Epoch 257/500, Train Loss: 0.4769364072851939\n",
      "Epoch 257/500, Validation Loss: 0.43776515330353827\n",
      "Epoch 258/500, Train Loss: 0.483163886282542\n",
      "Epoch 258/500, Validation Loss: 0.4329554806016896\n",
      "Epoch 259/500, Train Loss: 0.5119935368021874\n",
      "Epoch 259/500, Validation Loss: 0.47841625262613163\n",
      "Epoch 260/500, Train Loss: 0.47183677023404264\n",
      "Epoch 260/500, Validation Loss: 0.44137301347027086\n",
      "Epoch 261/500, Train Loss: 0.4700489109509612\n",
      "Epoch 261/500, Validation Loss: 0.43044895341951556\n",
      "Epoch 262/500, Train Loss: 0.4651475067008032\n",
      "Epoch 262/500, Validation Loss: 0.4319866716045223\n",
      "Epoch 263/500, Train Loss: 0.46902498153791033\n",
      "Epoch 263/500, Validation Loss: 0.4356452193978715\n",
      "Epoch 264/500, Train Loss: 0.5245492001102395\n",
      "Epoch 264/500, Validation Loss: 0.5007786718133378\n",
      "Epoch 265/500, Train Loss: 0.47153972191353366\n",
      "Epoch 265/500, Validation Loss: 0.42473230786519506\n",
      "Epoch 266/500, Train Loss: 0.467986916026024\n",
      "Epoch 266/500, Validation Loss: 0.4210489179990063\n",
      "Epoch 267/500, Train Loss: 0.46489927254311025\n",
      "Epoch 267/500, Validation Loss: 0.43195984461536147\n",
      "Epoch 268/500, Train Loss: 0.4654354551067091\n",
      "Epoch 268/500, Validation Loss: 0.431430749697228\n",
      "Epoch 269/500, Train Loss: 0.4731127538093149\n",
      "Epoch 269/500, Validation Loss: 0.4284815992394539\n",
      "Epoch 270/500, Train Loss: 0.4591239466242594\n",
      "Epoch 270/500, Validation Loss: 0.42172841094944574\n",
      "Epoch 271/500, Train Loss: 0.5123891838609356\n",
      "Epoch 271/500, Validation Loss: 0.48385325033370763\n",
      "Epoch 272/500, Train Loss: 0.47469603852049946\n",
      "Epoch 272/500, Validation Loss: 0.43105506570371865\n",
      "Epoch 273/500, Train Loss: 0.4658498429272273\n",
      "Epoch 273/500, Validation Loss: 0.43328618839995503\n",
      "Epoch 274/500, Train Loss: 0.4705360237866232\n",
      "Epoch 274/500, Validation Loss: 0.4399173741471277\n",
      "Epoch 275/500, Train Loss: 0.46339017071136057\n",
      "Epoch 275/500, Validation Loss: 0.4308773883401531\n",
      "Epoch 276/500, Train Loss: 0.46776023139692335\n",
      "Epoch 276/500, Validation Loss: 0.42178064013180666\n",
      "Epoch 277/500, Train Loss: 0.4638486545379848\n",
      "Epoch 277/500, Validation Loss: 0.42949084223133244\n",
      "Epoch 278/500, Train Loss: 0.46103083556645535\n",
      "Epoch 278/500, Validation Loss: 0.42297334295429595\n",
      "Epoch 279/500, Train Loss: 0.5115389938223852\n",
      "Epoch 279/500, Validation Loss: 0.46275053367222824\n",
      "Epoch 280/500, Train Loss: 0.4674816392872432\n",
      "Epoch 280/500, Validation Loss: 0.4308943274902971\n",
      "Epoch 281/500, Train Loss: 0.5151890834716901\n",
      "Epoch 281/500, Validation Loss: 0.47380513932606944\n",
      "Epoch 282/500, Train Loss: 0.4734686049696517\n",
      "Epoch 282/500, Validation Loss: 0.43626103744114914\n",
      "Epoch 283/500, Train Loss: 0.4573410933148371\n",
      "Epoch 283/500, Validation Loss: 0.418227831794791\n",
      "Epoch 284/500, Train Loss: 0.48289611772315144\n",
      "Epoch 284/500, Validation Loss: 0.4554714919769601\n",
      "Epoch 285/500, Train Loss: 0.45644337673709817\n",
      "Epoch 285/500, Validation Loss: 0.42169344751802207\n",
      "Epoch 286/500, Train Loss: 0.4676634759119112\n",
      "Epoch 286/500, Validation Loss: 0.4405457467248995\n",
      "Epoch 287/500, Train Loss: 0.4578564379313221\n",
      "Epoch 287/500, Validation Loss: 0.42237913118649834\n",
      "Epoch 288/500, Train Loss: 0.49156503808008484\n",
      "Epoch 288/500, Validation Loss: 0.4637393910590916\n",
      "Epoch 289/500, Train Loss: 0.45989462774093837\n",
      "Epoch 289/500, Validation Loss: 0.42818519023999774\n",
      "Epoch 290/500, Train Loss: 0.4692338651990237\n",
      "Epoch 290/500, Validation Loss: 0.4471794015740695\n",
      "Epoch 291/500, Train Loss: 0.4879272898582563\n",
      "Epoch 291/500, Validation Loss: 0.47030010370359027\n",
      "Epoch 292/500, Train Loss: 0.4996508886552837\n",
      "Epoch 292/500, Validation Loss: 0.48250156885957063\n",
      "Epoch 293/500, Train Loss: 0.45813136190584264\n",
      "Epoch 293/500, Validation Loss: 0.415004116215118\n",
      "Epoch 294/500, Train Loss: 0.46187370443997317\n",
      "Epoch 294/500, Validation Loss: 0.4365477317000089\n",
      "Epoch 295/500, Train Loss: 0.4626494139841158\n",
      "Epoch 295/500, Validation Loss: 0.4222644812440219\n",
      "Epoch 296/500, Train Loss: 0.4750813049812839\n",
      "Epoch 296/500, Validation Loss: 0.4551955853423027\n",
      "Epoch 297/500, Train Loss: 0.528216299945361\n",
      "Epoch 297/500, Validation Loss: 0.49862984598499455\n",
      "Epoch 298/500, Train Loss: 0.45763424365487815\n",
      "Epoch 298/500, Validation Loss: 0.4224473058360897\n",
      "Epoch 299/500, Train Loss: 0.467564877581923\n",
      "Epoch 299/500, Validation Loss: 0.4331305582229405\n",
      "Epoch 300/500, Train Loss: 0.4841641461196011\n",
      "Epoch 300/500, Validation Loss: 0.45308508938305997\n",
      "Epoch 301/500, Train Loss: 0.468846664445041\n",
      "Epoch 301/500, Validation Loss: 0.43157305905263715\n",
      "Epoch 302/500, Train Loss: 0.47429768353292384\n",
      "Epoch 302/500, Validation Loss: 0.4271736855376257\n",
      "Epoch 303/500, Train Loss: 0.47208846105288155\n",
      "Epoch 303/500, Validation Loss: 0.4189553775199472\n",
      "Epoch 304/500, Train Loss: 0.516276426511268\n",
      "Epoch 304/500, Validation Loss: 0.46365929793005123\n",
      "Epoch 305/500, Train Loss: 0.48344581666058056\n",
      "Epoch 305/500, Validation Loss: 0.4506925115846608\n",
      "Epoch 306/500, Train Loss: 0.5065242027583188\n",
      "Epoch 306/500, Validation Loss: 0.45387151633223444\n",
      "Epoch 307/500, Train Loss: 0.46403701705475375\n",
      "Epoch 307/500, Validation Loss: 0.4194278357780143\n",
      "Epoch 308/500, Train Loss: 0.466356342377728\n",
      "Epoch 308/500, Validation Loss: 0.41879454540879757\n",
      "Epoch 309/500, Train Loss: 0.534070316651096\n",
      "Epoch 309/500, Validation Loss: 0.47083353424725466\n",
      "Epoch 310/500, Train Loss: 0.4645435818254131\n",
      "Epoch 310/500, Validation Loss: 0.4302544308035341\n",
      "Epoch 311/500, Train Loss: 0.4680595740880052\n",
      "Epoch 311/500, Validation Loss: 0.439851705342123\n",
      "Epoch 312/500, Train Loss: 0.46466652212077625\n",
      "Epoch 312/500, Validation Loss: 0.43072895481161877\n",
      "Epoch 313/500, Train Loss: 0.4809939142775862\n",
      "Epoch 313/500, Validation Loss: 0.43409994367050797\n",
      "Epoch 314/500, Train Loss: 0.4761302511985988\n",
      "Epoch 314/500, Validation Loss: 0.4471522569656372\n",
      "Epoch 315/500, Train Loss: 0.45762232558368005\n",
      "Epoch 315/500, Validation Loss: 0.4225030304634408\n",
      "Epoch 316/500, Train Loss: 0.4717190882114515\n",
      "Epoch 316/500, Validation Loss: 0.4375036113882718\n",
      "Epoch 317/500, Train Loss: 0.4617151720066593\n",
      "Epoch 317/500, Validation Loss: 0.4259587199720618\n",
      "Epoch 318/500, Train Loss: 0.46420380309836506\n",
      "Epoch 318/500, Validation Loss: 0.4235776434205983\n",
      "Epoch 319/500, Train Loss: 0.47185149543905913\n",
      "Epoch 319/500, Validation Loss: 0.43184462557100267\n",
      "Epoch 320/500, Train Loss: 0.4607280521360162\n",
      "Epoch 320/500, Validation Loss: 0.4260558698275318\n",
      "Epoch 321/500, Train Loss: 0.45644837617874146\n",
      "Epoch 321/500, Validation Loss: 0.4193355767694238\n",
      "Epoch 322/500, Train Loss: 0.4749644602814766\n",
      "Epoch 322/500, Validation Loss: 0.4414309214239251\n",
      "Epoch 323/500, Train Loss: 0.45230100661107936\n",
      "Epoch 323/500, Validation Loss: 0.41990800753031693\n",
      "Epoch 324/500, Train Loss: 0.4535607989520243\n",
      "Epoch 324/500, Validation Loss: 0.4232791768361444\n",
      "Epoch 325/500, Train Loss: 0.5085132260845132\n",
      "Epoch 325/500, Validation Loss: 0.4584448762135963\n",
      "Epoch 326/500, Train Loss: 0.6191974837486058\n",
      "Epoch 326/500, Validation Loss: 0.5291216659219298\n",
      "Epoch 327/500, Train Loss: 0.4687030646082473\n",
      "Epoch 327/500, Validation Loss: 0.42466792178480595\n",
      "Epoch 328/500, Train Loss: 0.47674925196660706\n",
      "Epoch 328/500, Validation Loss: 0.4326485289286261\n",
      "Epoch 329/500, Train Loss: 0.45667883631301254\n",
      "Epoch 329/500, Validation Loss: 0.4184010722865797\n",
      "Epoch 330/500, Train Loss: 0.46408171359806843\n",
      "Epoch 330/500, Validation Loss: 0.4237817003302378\n",
      "Epoch 331/500, Train Loss: 0.4544356608227508\n",
      "Epoch 331/500, Validation Loss: 0.4171986857505694\n",
      "Epoch 332/500, Train Loss: 0.4622374119823926\n",
      "Epoch 332/500, Validation Loss: 0.41536252710917226\n",
      "Epoch 333/500, Train Loss: 0.4630842519133058\n",
      "Epoch 333/500, Validation Loss: 0.4147886037826538\n",
      "Epoch 334/500, Train Loss: 0.45473277405516743\n",
      "Epoch 334/500, Validation Loss: 0.4061946436150433\n",
      "Epoch 335/500, Train Loss: 0.45008669283292063\n",
      "Epoch 335/500, Validation Loss: 0.41136830146998576\n",
      "Epoch 336/500, Train Loss: 0.4992168733518418\n",
      "Epoch 336/500, Validation Loss: 0.45266834187181026\n",
      "Epoch 337/500, Train Loss: 0.4624408540660388\n",
      "Epoch 337/500, Validation Loss: 0.42256957700807757\n",
      "Epoch 338/500, Train Loss: 0.47836861463442243\n",
      "Epoch 338/500, Validation Loss: 0.43000771738078497\n",
      "Epoch 339/500, Train Loss: 0.4509497407364519\n",
      "Epoch 339/500, Validation Loss: 0.41705768973860025\n",
      "Epoch 340/500, Train Loss: 0.4681531117387014\n",
      "Epoch 340/500, Validation Loss: 0.4239176756715121\n",
      "Epoch 341/500, Train Loss: 0.4481531308121877\n",
      "Epoch 341/500, Validation Loss: 0.4060281694751896\n",
      "Epoch 342/500, Train Loss: 0.5124134151902917\n",
      "Epoch 342/500, Validation Loss: 0.4463533350866135\n",
      "Epoch 343/500, Train Loss: 0.4851044681790757\n",
      "Epoch 343/500, Validation Loss: 0.43990507926026434\n",
      "Epoch 344/500, Train Loss: 0.5756107960661797\n",
      "Epoch 344/500, Validation Loss: 0.48183217440565973\n",
      "Epoch 345/500, Train Loss: 0.47091484478075213\n",
      "Epoch 345/500, Validation Loss: 0.4423677178278361\n",
      "Epoch 346/500, Train Loss: 0.4565140286537066\n",
      "Epoch 346/500, Validation Loss: 0.4188300322179925\n",
      "Epoch 347/500, Train Loss: 0.5154062705497219\n",
      "Epoch 347/500, Validation Loss: 0.4711079699535892\n",
      "Epoch 348/500, Train Loss: 0.46648434049462617\n",
      "Epoch 348/500, Validation Loss: 0.4315864182498357\n",
      "Epoch 349/500, Train Loss: 0.4681954408345157\n",
      "Epoch 349/500, Validation Loss: 0.42552325007033676\n",
      "Epoch 350/500, Train Loss: 0.45052527483195476\n",
      "Epoch 350/500, Validation Loss: 0.4134225143145209\n",
      "Epoch 351/500, Train Loss: 0.4594908528131981\n",
      "Epoch 351/500, Validation Loss: 0.41397270274488895\n",
      "Epoch 352/500, Train Loss: 0.45430993748037785\n",
      "Epoch 352/500, Validation Loss: 0.4138302884689749\n",
      "Epoch 353/500, Train Loss: 0.46146100228779935\n",
      "Epoch 353/500, Validation Loss: 0.413251473479075\n",
      "Epoch 354/500, Train Loss: 0.48557188494564735\n",
      "Epoch 354/500, Validation Loss: 0.42305136135179705\n",
      "Epoch 355/500, Train Loss: 0.452751682637489\n",
      "Epoch 355/500, Validation Loss: 0.40696653764541835\n",
      "Epoch 356/500, Train Loss: 0.46041128692561634\n",
      "Epoch 356/500, Validation Loss: 0.4210185890328394\n",
      "Epoch 357/500, Train Loss: 0.4560118909568003\n",
      "Epoch 357/500, Validation Loss: 0.4312616545860081\n",
      "Epoch 358/500, Train Loss: 0.45747206635671117\n",
      "Epoch 358/500, Validation Loss: 0.4090844539746846\n",
      "Epoch 359/500, Train Loss: 0.4690748502130378\n",
      "Epoch 359/500, Validation Loss: 0.42315569397521346\n",
      "Epoch 360/500, Train Loss: 0.45700700846436904\n",
      "Epoch 360/500, Validation Loss: 0.41442350083834506\n",
      "Epoch 361/500, Train Loss: 0.4643098969165593\n",
      "Epoch 361/500, Validation Loss: 0.4253767042943876\n",
      "Epoch 362/500, Train Loss: 0.4623868408268445\n",
      "Epoch 362/500, Validation Loss: 0.41052028087720477\n",
      "Epoch 363/500, Train Loss: 0.450404310471391\n",
      "Epoch 363/500, Validation Loss: 0.41002564397576735\n",
      "Epoch 364/500, Train Loss: 0.44693090817699693\n",
      "Epoch 364/500, Validation Loss: 0.4079836272213557\n",
      "Epoch 365/500, Train Loss: 0.45467830847387447\n",
      "Epoch 365/500, Validation Loss: 0.40866042244924256\n",
      "Epoch 366/500, Train Loss: 0.4468167260901569\n",
      "Epoch 366/500, Validation Loss: 0.40557860266672424\n",
      "Epoch 367/500, Train Loss: 0.4565419362832422\n",
      "Epoch 367/500, Validation Loss: 0.427389384949044\n",
      "Epoch 368/500, Train Loss: 0.44798606552489817\n",
      "Epoch 368/500, Validation Loss: 0.4076400448198188\n",
      "Epoch 369/500, Train Loss: 0.4491073970925318\n",
      "Epoch 369/500, Validation Loss: 0.40917055329231367\n",
      "Epoch 370/500, Train Loss: 0.5212734402859047\n",
      "Epoch 370/500, Validation Loss: 0.45705759851899863\n",
      "Epoch 371/500, Train Loss: 0.5147206468941414\n",
      "Epoch 371/500, Validation Loss: 0.48914210518745527\n",
      "Epoch 372/500, Train Loss: 0.4673356903742438\n",
      "Epoch 372/500, Validation Loss: 0.42134162661147445\n",
      "Epoch 373/500, Train Loss: 0.4649946975381407\n",
      "Epoch 373/500, Validation Loss: 0.41922606344092384\n",
      "Epoch 374/500, Train Loss: 0.4513831457046613\n",
      "Epoch 374/500, Validation Loss: 0.4151442050933838\n",
      "Epoch 375/500, Train Loss: 0.6238892258030094\n",
      "Epoch 375/500, Validation Loss: 0.5419532819970013\n",
      "Epoch 376/500, Train Loss: 0.5598358005693514\n",
      "Epoch 376/500, Validation Loss: 0.5036236798926575\n",
      "Epoch 377/500, Train Loss: 0.455259769746702\n",
      "Epoch 377/500, Validation Loss: 0.4206015941214888\n",
      "Epoch 378/500, Train Loss: 0.45346780100913897\n",
      "Epoch 378/500, Validation Loss: 0.41561547207505734\n",
      "Epoch 379/500, Train Loss: 0.4747319609335024\n",
      "Epoch 379/500, Validation Loss: 0.4341696223167524\n",
      "Epoch 380/500, Train Loss: 0.4620258755063357\n",
      "Epoch 380/500, Validation Loss: 0.41697020481710567\n",
      "Epoch 381/500, Train Loss: 0.4556043850232477\n",
      "Epoch 381/500, Validation Loss: 0.41663818979916506\n",
      "Epoch 382/500, Train Loss: 0.4511888027191162\n",
      "Epoch 382/500, Validation Loss: 0.4073867283455313\n",
      "Epoch 383/500, Train Loss: 0.44922998057652824\n",
      "Epoch 383/500, Validation Loss: 0.40579707736838355\n",
      "Epoch 384/500, Train Loss: 0.44712803870031276\n",
      "Epoch 384/500, Validation Loss: 0.40588069615298755\n",
      "Epoch 385/500, Train Loss: 0.45867595076560974\n",
      "Epoch 385/500, Validation Loss: 0.42180849917947427\n",
      "Epoch 386/500, Train Loss: 0.4486422702057721\n",
      "Epoch 386/500, Validation Loss: 0.4081265403799815\n",
      "Epoch 387/500, Train Loss: 0.48212999595354683\n",
      "Epoch 387/500, Validation Loss: 0.42906969377439313\n",
      "Epoch 388/500, Train Loss: 0.4450640180339552\n",
      "Epoch 388/500, Validation Loss: 0.4039626325646492\n",
      "Epoch 389/500, Train Loss: 0.44239946179193995\n",
      "Epoch 389/500, Validation Loss: 0.4026009791517911\n",
      "Epoch 390/500, Train Loss: 0.4611986924524177\n",
      "Epoch 390/500, Validation Loss: 0.4149690629684762\n",
      "Epoch 391/500, Train Loss: 0.47532074908687644\n",
      "Epoch 391/500, Validation Loss: 0.4405745561808756\n",
      "Epoch 392/500, Train Loss: 0.44680101210123874\n",
      "Epoch 392/500, Validation Loss: 0.40777538492255017\n",
      "Epoch 393/500, Train Loss: 0.44527964845095597\n",
      "Epoch 393/500, Validation Loss: 0.4076811001725393\n",
      "Epoch 394/500, Train Loss: 0.4522834591669579\n",
      "Epoch 394/500, Validation Loss: 0.4156564955842005\n",
      "Epoch 395/500, Train Loss: 0.4538733105953426\n",
      "Epoch 395/500, Validation Loss: 0.40832135693667687\n",
      "Epoch 396/500, Train Loss: 0.4426233841948313\n",
      "Epoch 396/500, Validation Loss: 0.3995620077603484\n",
      "Epoch 397/500, Train Loss: 0.45762084975634537\n",
      "Epoch 397/500, Validation Loss: 0.4084371205878584\n",
      "Epoch 398/500, Train Loss: 0.4412282701224497\n",
      "Epoch 398/500, Validation Loss: 0.4058468370404962\n",
      "Epoch 399/500, Train Loss: 0.446122991712126\n",
      "Epoch 399/500, Validation Loss: 0.4017005758742764\n",
      "Epoch 400/500, Train Loss: 0.4532177946338915\n",
      "Epoch 400/500, Validation Loss: 0.4050582622828549\n",
      "Epoch 401/500, Train Loss: 0.44019347347625315\n",
      "Epoch 401/500, Validation Loss: 0.4007822985518469\n",
      "Epoch 402/500, Train Loss: 0.44828177478215464\n",
      "Epoch 402/500, Validation Loss: 0.41511738953525074\n",
      "Epoch 403/500, Train Loss: 0.4504481211100539\n",
      "Epoch 403/500, Validation Loss: 0.417062763481924\n",
      "Epoch 404/500, Train Loss: 0.450763368443267\n",
      "Epoch 404/500, Validation Loss: 0.41939926310761333\n",
      "Epoch 405/500, Train Loss: 0.4544399405178958\n",
      "Epoch 405/500, Validation Loss: 0.40717682038268\n",
      "Epoch 406/500, Train Loss: 0.43873843673157364\n",
      "Epoch 406/500, Validation Loss: 0.392666171674859\n",
      "Epoch 407/500, Train Loss: 0.46042702622609594\n",
      "Epoch 407/500, Validation Loss: 0.4239741743427433\n",
      "Epoch 408/500, Train Loss: 0.4312637336041829\n",
      "Epoch 408/500, Validation Loss: 0.39408826664702534\n",
      "Epoch 409/500, Train Loss: 0.5328945566530097\n",
      "Epoch 409/500, Validation Loss: 0.43159262121540226\n",
      "Epoch 410/500, Train Loss: 0.4464620702887235\n",
      "Epoch 410/500, Validation Loss: 0.40650246567922094\n",
      "Epoch 411/500, Train Loss: 0.46110221866058976\n",
      "Epoch 411/500, Validation Loss: 0.4237439795716168\n",
      "Epoch 412/500, Train Loss: 0.4371888417087189\n",
      "Epoch 412/500, Validation Loss: 0.40156777917522274\n",
      "Epoch 413/500, Train Loss: 0.467764190206789\n",
      "Epoch 413/500, Validation Loss: 0.4358596793592793\n",
      "Epoch 414/500, Train Loss: 0.4419454474971719\n",
      "Epoch 414/500, Validation Loss: 0.4102721826670921\n",
      "Epoch 415/500, Train Loss: 0.4362779198444053\n",
      "Epoch 415/500, Validation Loss: 0.3921690281123331\n",
      "Epoch 416/500, Train Loss: 0.42572242103210867\n",
      "Epoch 416/500, Validation Loss: 0.387021637942693\n",
      "Epoch 417/500, Train Loss: 0.4357955725225684\n",
      "Epoch 417/500, Validation Loss: 0.3989606997738146\n",
      "Epoch 418/500, Train Loss: 0.4259773407080402\n",
      "Epoch 418/500, Validation Loss: 0.3840892004640135\n",
      "Epoch 419/500, Train Loss: 0.5051068843227543\n",
      "Epoch 419/500, Validation Loss: 0.4410784807923722\n",
      "Epoch 420/500, Train Loss: 0.42479439630900345\n",
      "Epoch 420/500, Validation Loss: 0.38944359756495855\n",
      "Epoch 421/500, Train Loss: 0.42538149961053506\n",
      "Epoch 421/500, Validation Loss: 0.3915024399757385\n",
      "Epoch 422/500, Train Loss: 0.4293225007514431\n",
      "Epoch 422/500, Validation Loss: 0.3891117662599642\n",
      "Epoch 423/500, Train Loss: 0.4904018415980143\n",
      "Epoch 423/500, Validation Loss: 0.42918594814326666\n",
      "Epoch 424/500, Train Loss: 0.46743596090029366\n",
      "Epoch 424/500, Validation Loss: 0.4334560767428516\n",
      "Epoch 425/500, Train Loss: 0.4274990199363395\n",
      "Epoch 425/500, Validation Loss: 0.39127825302620456\n",
      "Epoch 426/500, Train Loss: 0.44829463958740234\n",
      "Epoch 426/500, Validation Loss: 0.40009446503364876\n",
      "Epoch 427/500, Train Loss: 0.42935864361998155\n",
      "Epoch 427/500, Validation Loss: 0.39644769324015267\n",
      "Epoch 428/500, Train Loss: 0.42390005433396116\n",
      "Epoch 428/500, Validation Loss: 0.39025896175266944\n",
      "Epoch 429/500, Train Loss: 0.4181590880433174\n",
      "Epoch 429/500, Validation Loss: 0.3855524042697802\n",
      "Epoch 430/500, Train Loss: 0.41480504568309\n",
      "Epoch 430/500, Validation Loss: 0.3760889409339591\n",
      "Epoch 431/500, Train Loss: 0.4494394476283087\n",
      "Epoch 431/500, Validation Loss: 0.39668473152265155\n",
      "Epoch 432/500, Train Loss: 0.4218273048531519\n",
      "Epoch 432/500, Validation Loss: 0.3809178022489156\n",
      "Epoch 433/500, Train Loss: 0.5512219520464335\n",
      "Epoch 433/500, Validation Loss: 0.44883275399469347\n",
      "Epoch 434/500, Train Loss: 0.41837914839182816\n",
      "Epoch 434/500, Validation Loss: 0.38527660990414553\n",
      "Epoch 435/500, Train Loss: 0.41663955580698303\n",
      "Epoch 435/500, Validation Loss: 0.3822534859996952\n",
      "Epoch 436/500, Train Loss: 0.41048669243512087\n",
      "Epoch 436/500, Validation Loss: 0.374395001016251\n",
      "Epoch 437/500, Train Loss: 0.4182555112120223\n",
      "Epoch 437/500, Validation Loss: 0.3782643875847124\n",
      "Epoch 438/500, Train Loss: 0.4750319433538881\n",
      "Epoch 438/500, Validation Loss: 0.44251927692596227\n",
      "Epoch 439/500, Train Loss: 0.4637140256084808\n",
      "Epoch 439/500, Validation Loss: 0.4059609003262977\n",
      "Epoch 440/500, Train Loss: 0.410960025166812\n",
      "Epoch 440/500, Validation Loss: 0.37314001011521847\n",
      "Epoch 441/500, Train Loss: 0.46699399041802914\n",
      "Epoch 441/500, Validation Loss: 0.416845195913968\n",
      "Epoch 442/500, Train Loss: 0.5267513663801429\n",
      "Epoch 442/500, Validation Loss: 0.4532690154363031\n",
      "Epoch 443/500, Train Loss: 0.42203310050376475\n",
      "Epoch 443/500, Validation Loss: 0.3917339656450977\n",
      "Epoch 444/500, Train Loss: 0.40886481902370714\n",
      "Epoch 444/500, Validation Loss: 0.3724051542478065\n",
      "Epoch 445/500, Train Loss: 0.48760244331947744\n",
      "Epoch 445/500, Validation Loss: 0.4100985886299447\n",
      "Epoch 446/500, Train Loss: 0.4331449041627858\n",
      "Epoch 446/500, Validation Loss: 0.3972195786972568\n",
      "Epoch 447/500, Train Loss: 0.40244871745370836\n",
      "Epoch 447/500, Validation Loss: 0.36138274898267775\n",
      "Epoch 448/500, Train Loss: 0.41449573227804\n",
      "Epoch 448/500, Validation Loss: 0.36759677815110714\n",
      "Epoch 449/500, Train Loss: 0.4453853681071164\n",
      "Epoch 449/500, Validation Loss: 0.4094268271367844\n",
      "Epoch 450/500, Train Loss: 0.4538776992935024\n",
      "Epoch 450/500, Validation Loss: 0.39060921864966824\n",
      "Epoch 451/500, Train Loss: 0.39278788599249437\n",
      "Epoch 451/500, Validation Loss: 0.3543638774793442\n",
      "Epoch 452/500, Train Loss: 0.4407864706973507\n",
      "Epoch 452/500, Validation Loss: 0.3909109643060867\n",
      "Epoch 453/500, Train Loss: 0.43301322811270415\n",
      "Epoch 453/500, Validation Loss: 0.40351593984316475\n",
      "Epoch 454/500, Train Loss: 0.38698957390981176\n",
      "Epoch 454/500, Validation Loss: 0.35515815917759724\n",
      "Epoch 455/500, Train Loss: 0.3768829242007373\n",
      "Epoch 455/500, Validation Loss: 0.34616074905003585\n",
      "Epoch 456/500, Train Loss: 0.43667704928411194\n",
      "Epoch 456/500, Validation Loss: 0.3835900156465295\n",
      "Epoch 457/500, Train Loss: 0.3789871816765772\n",
      "Epoch 457/500, Validation Loss: 0.33885292525160804\n",
      "Epoch 458/500, Train Loss: 0.3864431515948413\n",
      "Epoch 458/500, Validation Loss: 0.35345447104271144\n",
      "Epoch 459/500, Train Loss: 0.38419426222370096\n",
      "Epoch 459/500, Validation Loss: 0.3536104453753119\n",
      "Epoch 460/500, Train Loss: 0.366369852056242\n",
      "Epoch 460/500, Validation Loss: 0.3329425960370939\n",
      "Epoch 461/500, Train Loss: 0.4135442719067613\n",
      "Epoch 461/500, Validation Loss: 0.3655144498772817\n",
      "Epoch 462/500, Train Loss: 0.37011906463805944\n",
      "Epoch 462/500, Validation Loss: 0.3374593098686166\n",
      "Epoch 463/500, Train Loss: 0.364451480646656\n",
      "Epoch 463/500, Validation Loss: 0.3285246226069045\n",
      "Epoch 464/500, Train Loss: 0.37134242527288935\n",
      "Epoch 464/500, Validation Loss: 0.3345190164161055\n",
      "Epoch 465/500, Train Loss: 0.3706779169709715\n",
      "Epoch 465/500, Validation Loss: 0.3464889550862247\n",
      "Epoch 466/500, Train Loss: 0.4304281150641507\n",
      "Epoch 466/500, Validation Loss: 0.40849141225422897\n",
      "Epoch 467/500, Train Loss: 0.36873923670755676\n",
      "Epoch 467/500, Validation Loss: 0.3309002094072838\n",
      "Epoch 468/500, Train Loss: 0.36826678008249364\n",
      "Epoch 468/500, Validation Loss: 0.33632258397259124\n",
      "Epoch 469/500, Train Loss: 0.3762067384915809\n",
      "Epoch 469/500, Validation Loss: 0.34772164976760134\n",
      "Epoch 470/500, Train Loss: 0.3609648587769025\n",
      "Epoch 470/500, Validation Loss: 0.332404177482814\n",
      "Epoch 471/500, Train Loss: 0.42873032207358375\n",
      "Epoch 471/500, Validation Loss: 0.4049584483855391\n",
      "Epoch 472/500, Train Loss: 0.36110507176346973\n",
      "Epoch 472/500, Validation Loss: 0.32912188115185254\n",
      "Epoch 473/500, Train Loss: 0.37812408274167203\n",
      "Epoch 473/500, Validation Loss: 0.33391078980001687\n",
      "Epoch 474/500, Train Loss: 0.3890403560171389\n",
      "Epoch 474/500, Validation Loss: 0.3561577119239389\n",
      "Epoch 475/500, Train Loss: 0.3954596952216266\n",
      "Epoch 475/500, Validation Loss: 0.3473335222838676\n",
      "Epoch 476/500, Train Loss: 0.5388804988501823\n",
      "Epoch 476/500, Validation Loss: 0.44032559492816664\n",
      "Epoch 477/500, Train Loss: 0.37695153077987775\n",
      "Epoch 477/500, Validation Loss: 0.3486717418856817\n",
      "Epoch 478/500, Train Loss: 0.6672771491416513\n",
      "Epoch 478/500, Validation Loss: 0.5481218369039771\n",
      "Epoch 479/500, Train Loss: 0.36674576262905173\n",
      "Epoch 479/500, Validation Loss: 0.33308025786321455\n",
      "Epoch 480/500, Train Loss: 0.4213505652669358\n",
      "Epoch 480/500, Validation Loss: 0.391294585515375\n",
      "Epoch 481/500, Train Loss: 0.3485796280103187\n",
      "Epoch 481/500, Validation Loss: 0.31222387413456015\n",
      "Epoch 482/500, Train Loss: 0.41275167873460955\n",
      "Epoch 482/500, Validation Loss: 0.3775854176037932\n",
      "Epoch 483/500, Train Loss: 0.36037375869816296\n",
      "Epoch 483/500, Validation Loss: 0.3253332217262216\n",
      "Epoch 484/500, Train Loss: 0.3475802677543196\n",
      "Epoch 484/500, Validation Loss: 0.31219923251295745\n",
      "Epoch 485/500, Train Loss: 0.3543187832995637\n",
      "Epoch 485/500, Validation Loss: 0.3163635240842218\n",
      "Epoch 486/500, Train Loss: 0.3659888269150094\n",
      "Epoch 486/500, Validation Loss: 0.3231425497629871\n",
      "Epoch 487/500, Train Loss: 0.3454643226649663\n",
      "Epoch 487/500, Validation Loss: 0.3285701368769554\n",
      "Epoch 488/500, Train Loss: 0.36745738983154297\n",
      "Epoch 488/500, Validation Loss: 0.34371187343989335\n",
      "Epoch 489/500, Train Loss: 0.3333743790241137\n",
      "Epoch 489/500, Validation Loss: 0.3014531102899003\n",
      "Epoch 490/500, Train Loss: 0.3486650112557085\n",
      "Epoch 490/500, Validation Loss: 0.3092985418561387\n",
      "Epoch 491/500, Train Loss: 0.3669565042404279\n",
      "Epoch 491/500, Validation Loss: 0.32474103243383645\n",
      "Epoch 492/500, Train Loss: 0.3675554949943333\n",
      "Epoch 492/500, Validation Loss: 0.3245386844628478\n",
      "Epoch 493/500, Train Loss: 0.3586297488375886\n",
      "Epoch 493/500, Validation Loss: 0.3270020738039931\n",
      "Epoch 494/500, Train Loss: 0.3882107451966364\n",
      "Epoch 494/500, Validation Loss: 0.3567205308234855\n",
      "Epoch 495/500, Train Loss: 0.4300257988172035\n",
      "Epoch 495/500, Validation Loss: 0.3748459571028409\n",
      "Epoch 496/500, Train Loss: 0.3405063176808292\n",
      "Epoch 496/500, Validation Loss: 0.3052006106670589\n",
      "Epoch 497/500, Train Loss: 0.325698829268756\n",
      "Epoch 497/500, Validation Loss: 0.29806699369051687\n",
      "Epoch 498/500, Train Loss: 0.3312128723075945\n",
      "Epoch 498/500, Validation Loss: 0.2983058797170038\n",
      "Epoch 499/500, Train Loss: 0.35159253869971185\n",
      "Epoch 499/500, Validation Loss: 0.32478251032633326\n",
      "Epoch 500/500, Train Loss: 0.32829624291968673\n",
      "Epoch 500/500, Validation Loss: 0.2944659284532887\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.train_model(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training and validation losses\n",
    "plt.plot(range(1, model.num_epochs + 1), model.train_losses, label='Train Loss')\n",
    "plt.plot(range(1, model.num_epochs + 1), model.val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_train = model.predict(X_train_tensor).numpy()\n",
    "y_pred_test = model.predict(X_test_tensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.860445205479452\n",
      "Test Accuracy: 0.8801369863013698\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Train Data:\n",
      "[[501  70]\n",
      " [ 93 504]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(\"Confusion Matrix for Train Data:\")\n",
    "print(confusion_matrix(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Test Data:\n",
      "[[145  16]\n",
      " [ 19 112]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix for Test Data:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
