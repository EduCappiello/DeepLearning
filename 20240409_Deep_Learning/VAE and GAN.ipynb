{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "DataSolarModules = pd.read_json('InfraredSolarModules/module_metadata.json').transpose().sort_index()\n",
    "\n",
    "# Define classes and map them to numbers\n",
    "Classes = DataSolarModules['anomaly_class'].unique()\n",
    "class_to_number = {v: k for k, v in enumerate(Classes)}\n",
    "\n",
    "# Map class to number\n",
    "DataSolarModules['class_code'] = DataSolarModules['anomaly_class'].map(class_to_number)\n",
    "\n",
    "# Define functions to read images and labels\n",
    "def read_images_dataframe(dataframe):\n",
    "    images = []\n",
    "    for image_path in dataframe['image_filepath']:\n",
    "        img = cv2.imread(\"InfraredSolarModules/\"+image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.reshape(40, 24).astype(\"float32\") / 255\n",
    "        images.append(img)\n",
    "    images = np.array(images) \n",
    "    return images\n",
    "\n",
    "def read_labels_dataframe(dataframe):\n",
    "    labels = dataframe['class_code'].values.astype(\"int64\")\n",
    "    return labels\n",
    "\n",
    "# Read images and labels\n",
    "images = read_images_dataframe(DataSolarModules)\n",
    "labels = read_labels_dataframe(DataSolarModules)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "images_tensor = torch.tensor(images).to(device)\n",
    "labels_tensor = torch.tensor(labels).to(device)\n",
    "\n",
    "# Define dataset and dataloader\n",
    "dataset = TensorDataset(images_tensor, labels_tensor)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GAN architectures\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 40 * 24),\n",
    "            nn.Tanh()  # To get pixel values between -1 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, 40, 24)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(40 * 24, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "# Training function for GAN\n",
    "def train_gan(generator, discriminator, gan_optimizer_G, gan_optimizer_D, device, train_loader, epochs=10, n_critic=5, clip_value=0.01):\n",
    "    adversarial_loss = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, (imgs, _) in enumerate(train_loader):\n",
    "\n",
    "            # Adversarial ground truths\n",
    "            valid = torch.ones(imgs.size(0), 1).to(device)\n",
    "            fake = torch.zeros(imgs.size(0), 1).to(device)\n",
    "\n",
    "            # Configure input\n",
    "            real_imgs = imgs.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            # ----------------- #\n",
    "            #  Train Generator  #\n",
    "            # ----------------- #\n",
    "\n",
    "            gan_optimizer_G.zero_grad()\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            z = torch.randn(imgs.shape[0], 100).to(device)\n",
    "\n",
    "            # Generate a batch of images\n",
    "            gen_imgs = generator(z)\n",
    "\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "            g_loss.backward()\n",
    "            gan_optimizer_G.step()\n",
    "\n",
    "            # --------------------- #\n",
    "            #  Train Discriminator  #\n",
    "            # --------------------- #\n",
    "\n",
    "            for _ in range(n_critic):\n",
    "                gan_optimizer_D.zero_grad()\n",
    "\n",
    "                # Measure discriminator's ability to classify real from generated samples\n",
    "                real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "                fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "                d_loss.backward()\n",
    "                gan_optimizer_D.step()\n",
    "\n",
    "                # Clip weights of discriminator\n",
    "                for p in discriminator.parameters():\n",
    "                    p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, epochs, i, len(train_loader), d_loss.item(), g_loss.item())\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VAE architecture\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(40 * 24, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 40 * 24),\n",
    "            nn.Sigmoid()  # To get pixel values between 0 and 1\n",
    "        )\n",
    "\n",
    "        self.mu_layer = nn.Linear(64, 64)\n",
    "        self.logvar_layer = nn.Linear(64, 64)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 40 * 24)\n",
    "        h = self.encoder(x)\n",
    "        mu = self.mu_layer(h)\n",
    "        logvar = self.logvar_layer(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        decoded = self.decoder(z)\n",
    "        return decoded, mu, logvar\n",
    "\n",
    "# Loss function for VAE\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, 40 * 24), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# Training function for VAE\n",
    "def train_vae(vae, train_loader, optimizer, device, epochs=10):\n",
    "    vae.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = vae(data)\n",
    "            loss = vae_loss(recon_batch, data, mu, logvar)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        print('Epoch {}, Average Loss: {:.4f}'.format(epoch+1, total_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GAN models, optimizers, and train\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "train_gan(generator, discriminator, optimizer_G, optimizer_D, device, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VAE model, optimizer, and train\n",
    "vae = VAE().to(device)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "train_vae(vae, train_loader, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.transforms.functional import resize\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to generate and save images\n",
    "def generate_images_per_class(model, model_type, device, n_samples=10, image_size=(40, 24)):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for class_code, class_name in enumerate(Classes):\n",
    "            # Create a folder for each class\n",
    "            class_folder = os.path.join(save_dir, model_type, class_name)\n",
    "            os.makedirs(class_folder, exist_ok=True)\n",
    "            \n",
    "            if model_type == \"GAN\":\n",
    "                z = torch.randn(n_samples, 100).to(device)\n",
    "                gen_imgs = model(z)\n",
    "            elif model_type == \"VAE\":\n",
    "                z = torch.randn(n_samples, 64).to(device)\n",
    "                gen_imgs = model.decoder(z)\n",
    "                # Reshape to include channel dimension\n",
    "                gen_imgs = gen_imgs.view(-1, 1, image_size[0], image_size[1])\n",
    "            else:\n",
    "                raise ValueError(\"Invalid model type. Use 'GAN' or 'VAE'.\")\n",
    "            \n",
    "            # Save individual images\n",
    "            for i in range(n_samples):\n",
    "                image = gen_imgs[i].cpu().numpy()\n",
    "                \n",
    "                # Save the image\n",
    "                image = image.squeeze() * 255  # Scale to 0-255\n",
    "                image = image.astype('uint8')  # Convert to uint8\n",
    "                image_path = os.path.join(class_folder, f\"{model_type}_generated_{i}.png\")\n",
    "                cv2.imwrite(image_path, image)\n",
    "\n",
    "# Define a directory to save the generated images\n",
    "save_dir = \"generated_images\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save images for GAN\n",
    "generate_images_per_class(generator, \"GAN\", device)\n",
    "\n",
    "# Generate and save images for VAE\n",
    "generate_images_per_class(vae, \"VAE\", device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
